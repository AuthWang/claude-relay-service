#!/usr/bin/env node

/**
 * üóÑÔ∏è Claude Relay Service - Êï∞ÊçÆÂ∫ìÂàùÂßãÂåñËÑöÊú¨
 *
 * Ëá™Âä®ÂàõÂª∫PostgreSQLË°®ÁªìÊûÑÂíåÁ¥¢Âºï
 * Created by DevOps-Expert with SMART-6 optimization
 */

const { Pool } = require('pg')
const winston = require('winston')
const path = require('path')

// ÈÖçÁΩÆÊó•Âøó
const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.colorize(),
    winston.format.printf(({ timestamp, level, message }) => `${timestamp} [${level}] ${message}`)
  ),
  transports: [
    new winston.transports.Console(),
    new winston.transports.File({
      filename: path.join(__dirname, '../logs/database-init.log'),
      maxsize: 10 * 1024 * 1024,
      maxFiles: 3
    })
  ]
})

class DatabaseInitializer {
  constructor() {
    this.pool = null
    this.tables = this.getTableDefinitions()
  }

  async initialize() {
    logger.info('üóÑÔ∏è ÂàùÂßãÂåñÊï∞ÊçÆÂ∫ìËøûÊé•...')

    this.pool = new Pool({
      host: process.env.POSTGRES_HOST || 'localhost',
      port: process.env.POSTGRES_PORT || 5432,
      database: process.env.POSTGRES_DATABASE || 'claude_relay',
      user: process.env.POSTGRES_USER || 'postgres',
      password: String(process.env.POSTGRES_PASSWORD || ''),
      max: 5,
      idleTimeoutMillis: 30000,
      connectionTimeoutMillis: 5000,
      ssl:
        process.env.POSTGRES_SSL_ENABLED === 'true'
          ? {
              rejectUnauthorized: process.env.POSTGRES_SSL_REJECT_UNAUTHORIZED !== 'false'
            }
          : false
    })

    // ÊµãËØïËøûÊé•
    const client = await this.pool.connect()
    await client.query('SELECT NOW()')
    client.release()

    logger.info('‚úÖ Êï∞ÊçÆÂ∫ìËøûÊé•ÊàêÂäü')
  }

  getTableDefinitions() {
    return {
      // API KeysË°®
      api_keys: {
        schema: `
          CREATE TABLE IF NOT EXISTS api_keys (
            id VARCHAR(64) PRIMARY KEY,
            api_key_hash VARCHAR(128) UNIQUE NOT NULL,
            name VARCHAR(255) NOT NULL DEFAULT 'API Key',
            token_limit BIGINT NOT NULL DEFAULT 1000000,
            token_used BIGINT NOT NULL DEFAULT 0,
            is_active BOOLEAN NOT NULL DEFAULT true,
            expires_at TIMESTAMP,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
          )
        `,
        indexes: [
          'CREATE INDEX IF NOT EXISTS idx_api_keys_hash ON api_keys(api_key_hash)',
          'CREATE INDEX IF NOT EXISTS idx_api_keys_active ON api_keys(is_active) WHERE is_active = true',
          'CREATE INDEX IF NOT EXISTS idx_api_keys_expires ON api_keys(expires_at) WHERE expires_at IS NOT NULL'
        ],
        description: 'APIÂØÜÈí•ÁÆ°ÁêÜË°®'
      },

      // ClaudeË¥¶Êà∑Ë°®
      claude_accounts: {
        schema: `
          CREATE TABLE IF NOT EXISTS claude_accounts (
            id VARCHAR(64) PRIMARY KEY,
            name VARCHAR(255) NOT NULL,
            description TEXT DEFAULT '',
            claude_ai_oauth TEXT, -- Âä†ÂØÜÂ≠òÂÇ®ÁöÑOAuthÊï∞ÊçÆ
            proxy_config JSONB,
            is_active BOOLEAN NOT NULL DEFAULT true,
            is_rate_limited BOOLEAN NOT NULL DEFAULT false,
            rate_limit_until TIMESTAMP,
            request_count BIGINT NOT NULL DEFAULT 0,
            last_used_at TIMESTAMP,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
          )
        `,
        indexes: [
          'CREATE INDEX IF NOT EXISTS idx_claude_accounts_active ON claude_accounts(is_active) WHERE is_active = true',
          'CREATE INDEX IF NOT EXISTS idx_claude_accounts_rate_limited ON claude_accounts(is_rate_limited, rate_limit_until) WHERE is_rate_limited = true',
          'CREATE INDEX IF NOT EXISTS idx_claude_accounts_last_used ON claude_accounts(last_used_at)',
          'CREATE INDEX IF NOT EXISTS idx_claude_accounts_proxy ON claude_accounts USING GIN(proxy_config) WHERE proxy_config IS NOT NULL'
        ],
        description: 'ClaudeË¥¶Êà∑ÁÆ°ÁêÜË°®'
      },

      // GeminiË¥¶Êà∑Ë°®
      gemini_accounts: {
        schema: `
          CREATE TABLE IF NOT EXISTS gemini_accounts (
            id VARCHAR(64) PRIMARY KEY,
            name VARCHAR(255) NOT NULL,
            description TEXT DEFAULT '',
            google_oauth TEXT, -- Âä†ÂØÜÂ≠òÂÇ®ÁöÑOAuthÊï∞ÊçÆ
            proxy_config JSONB,
            is_active BOOLEAN NOT NULL DEFAULT true,
            is_rate_limited BOOLEAN NOT NULL DEFAULT false,
            rate_limit_until TIMESTAMP,
            request_count BIGINT NOT NULL DEFAULT 0,
            last_used_at TIMESTAMP,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
          )
        `,
        indexes: [
          'CREATE INDEX IF NOT EXISTS idx_gemini_accounts_active ON gemini_accounts(is_active) WHERE is_active = true',
          'CREATE INDEX IF NOT EXISTS idx_gemini_accounts_rate_limited ON gemini_accounts(is_rate_limited, rate_limit_until) WHERE is_rate_limited = true',
          'CREATE INDEX IF NOT EXISTS idx_gemini_accounts_last_used ON gemini_accounts(last_used_at)'
        ],
        description: 'GeminiË¥¶Êà∑ÁÆ°ÁêÜË°®'
      },

      // ÁÆ°ÁêÜÂëòË°®
      admins: {
        schema: `
          CREATE TABLE IF NOT EXISTS admins (
            id VARCHAR(64) PRIMARY KEY,
            username VARCHAR(255) UNIQUE NOT NULL,
            password_hash VARCHAR(255) NOT NULL,
            is_active BOOLEAN NOT NULL DEFAULT true,
            last_login_at TIMESTAMP,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
          )
        `,
        indexes: [
          'CREATE UNIQUE INDEX IF NOT EXISTS idx_admins_username ON admins(username)',
          'CREATE INDEX IF NOT EXISTS idx_admins_active ON admins(is_active) WHERE is_active = true'
        ],
        description: 'ÁÆ°ÁêÜÂëòË¥¶Êà∑Ë°®'
      },

      // ‰ΩøÁî®ÁªüËÆ°Ë°®
      usage_statistics: {
        schema: `
          CREATE TABLE IF NOT EXISTS usage_statistics (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            date DATE NOT NULL,
            api_key_id VARCHAR(64) NOT NULL,
            model VARCHAR(100) NOT NULL,
            request_count BIGINT NOT NULL DEFAULT 0,
            token_count BIGINT NOT NULL DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            CONSTRAINT fk_usage_api_key FOREIGN KEY (api_key_id) REFERENCES api_keys(id) ON DELETE CASCADE
          )
        `,
        indexes: [
          'CREATE UNIQUE INDEX IF NOT EXISTS idx_usage_unique ON usage_statistics(date, api_key_id, model)',
          'CREATE INDEX IF NOT EXISTS idx_usage_date ON usage_statistics(date)',
          'CREATE INDEX IF NOT EXISTS idx_usage_api_key ON usage_statistics(api_key_id)',
          'CREATE INDEX IF NOT EXISTS idx_usage_model ON usage_statistics(model)',
          'CREATE INDEX IF NOT EXISTS idx_usage_date_model ON usage_statistics(date, model)'
        ],
        description: '‰ΩøÁî®ÁªüËÆ°Ë°®'
      },

      // ‰ºöËØùË°®
      sessions: {
        schema: `
          CREATE TABLE IF NOT EXISTS sessions (
            id VARCHAR(128) PRIMARY KEY,
            admin_id VARCHAR(64) NOT NULL,
            data JSONB,
            expires_at TIMESTAMP NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            CONSTRAINT fk_sessions_admin FOREIGN KEY (admin_id) REFERENCES admins(id) ON DELETE CASCADE
          )
        `,
        indexes: [
          'CREATE INDEX IF NOT EXISTS idx_sessions_admin ON sessions(admin_id)',
          'CREATE INDEX IF NOT EXISTS idx_sessions_expires ON sessions(expires_at)',
          'CREATE INDEX IF NOT EXISTS idx_sessions_data ON sessions USING GIN(data) WHERE data IS NOT NULL'
        ],
        description: '‰ºöËØùÁÆ°ÁêÜË°®'
      },

      // Á≥ªÁªüÊó•ÂøóË°®
      system_logs: {
        schema: `
          CREATE TABLE IF NOT EXISTS system_logs (
            id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
            level VARCHAR(20) NOT NULL,
            message TEXT NOT NULL,
            metadata JSONB,
            component VARCHAR(100),
            api_key_id VARCHAR(64),
            account_id VARCHAR(64),
            ip_address INET,
            user_agent TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
          )
        `,
        indexes: [
          'CREATE INDEX IF NOT EXISTS idx_logs_level ON system_logs(level)',
          'CREATE INDEX IF NOT EXISTS idx_logs_component ON system_logs(component)',
          'CREATE INDEX IF NOT EXISTS idx_logs_created_at ON system_logs(created_at)',
          'CREATE INDEX IF NOT EXISTS idx_logs_api_key ON system_logs(api_key_id) WHERE api_key_id IS NOT NULL',
          'CREATE INDEX IF NOT EXISTS idx_logs_account ON system_logs(account_id) WHERE account_id IS NOT NULL',
          'CREATE INDEX IF NOT EXISTS idx_logs_metadata ON system_logs USING GIN(metadata) WHERE metadata IS NOT NULL'
        ],
        description: 'Á≥ªÁªüÊó•ÂøóË°®'
      },

      // Á≥ªÁªüÈÖçÁΩÆË°®
      system_configs: {
        schema: `
          CREATE TABLE IF NOT EXISTS system_configs (
            key VARCHAR(255) PRIMARY KEY,
            value JSONB NOT NULL,
            description TEXT,
            is_encrypted BOOLEAN NOT NULL DEFAULT false,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
          )
        `,
        indexes: [
          'CREATE INDEX IF NOT EXISTS idx_configs_encrypted ON system_configs(is_encrypted) WHERE is_encrypted = true'
        ],
        description: 'Á≥ªÁªüÈÖçÁΩÆË°®'
      }
    }
  }

  async createDatabase() {
    logger.info('üèóÔ∏è ÂºÄÂßãÂàõÂª∫Êï∞ÊçÆÂ∫ìË°®ÁªìÊûÑ...')

    const client = await this.pool.connect()

    try {
      await client.query('BEGIN')

      // Á°Æ‰øùUUIDÊâ©Â±ïÂ≠òÂú®
      await client.query('CREATE EXTENSION IF NOT EXISTS "uuid-ossp"')
      await client.query('CREATE EXTENSION IF NOT EXISTS "pg_stat_statements"')

      logger.info('‚úÖ Êï∞ÊçÆÂ∫ìÊâ©Â±ïÂ∑≤ÂêØÁî®')

      // ÂàõÂª∫Ë°®
      for (const [tableName, tableConfig] of Object.entries(this.tables)) {
        logger.info(`üìã ÂàõÂª∫Ë°®: ${tableName}`)

        // ÂàõÂª∫Ë°®ÁªìÊûÑ
        await client.query(tableConfig.schema)
        logger.info(`  ‚úÖ Ë°®ÁªìÊûÑÂàõÂª∫ÂÆåÊàê: ${tableName}`)

        // ÂàõÂª∫Á¥¢Âºï
        for (const indexQuery of tableConfig.indexes) {
          await client.query(indexQuery)
        }
        logger.info(`  ‚úÖ Á¥¢ÂºïÂàõÂª∫ÂÆåÊàê: ${tableName} (${tableConfig.indexes.length}‰∏™)`)
      }

      // ÂàõÂª∫Ëß¶ÂèëÂô®ÂáΩÊï∞
      await this.createTriggers(client)

      // ÊèíÂÖ•ÂàùÂßãÊï∞ÊçÆ
      await this.insertInitialData(client)

      await client.query('COMMIT')
      logger.info('üéâ Êï∞ÊçÆÂ∫ìÁªìÊûÑÂàõÂª∫ÂÆåÊàêÔºÅ')
    } catch (error) {
      await client.query('ROLLBACK')
      throw error
    } finally {
      client.release()
    }
  }

  async createTriggers(client) {
    logger.info('‚ö° ÂàõÂª∫Ëß¶ÂèëÂô®...')

    // Ëá™Âä®Êõ¥Êñ∞ updated_at Â≠óÊÆµÁöÑËß¶ÂèëÂô®ÂáΩÊï∞
    const updateTimestampFunction = `
      CREATE OR REPLACE FUNCTION update_updated_at_column()
      RETURNS TRIGGER AS $$
      BEGIN
        NEW.updated_at = CURRENT_TIMESTAMP;
        RETURN NEW;
      END;
      $$ language 'plpgsql';
    `

    await client.query(updateTimestampFunction)

    // ‰∏∫ÈúÄË¶ÅÁöÑË°®Ê∑ªÂä†Ëß¶ÂèëÂô®
    const tablesWithUpdateTrigger = [
      'api_keys',
      'claude_accounts',
      'gemini_accounts',
      'admins',
      'usage_statistics',
      'sessions',
      'system_configs'
    ]

    for (const tableName of tablesWithUpdateTrigger) {
      const triggerQuery = `
        DROP TRIGGER IF EXISTS update_${tableName}_updated_at ON ${tableName};
        CREATE TRIGGER update_${tableName}_updated_at
          BEFORE UPDATE ON ${tableName}
          FOR EACH ROW
          EXECUTE FUNCTION update_updated_at_column();
      `

      await client.query(triggerQuery)
      logger.info(`  ‚úÖ Ëß¶ÂèëÂô®ÂàõÂª∫ÂÆåÊàê: ${tableName}`)
    }

    logger.info('‚úÖ ÊâÄÊúâËß¶ÂèëÂô®ÂàõÂª∫ÂÆåÊàê')
  }

  async insertInitialData(client) {
    logger.info('üìù ÊèíÂÖ•ÂàùÂßãÊï∞ÊçÆ...')

    // ÊèíÂÖ•Á≥ªÁªüÈÖçÁΩÆ
    const systemConfigs = [
      {
        key: 'database_version',
        value: JSON.stringify({ version: '1.0.0', created_at: new Date().toISOString() }),
        description: 'Êï∞ÊçÆÂ∫ìÁâàÊú¨‰ø°ÊÅØ'
      },
      {
        key: 'migration_status',
        value: JSON.stringify({ completed: false, last_migration: null }),
        description: 'Êï∞ÊçÆËøÅÁßªÁä∂ÊÄÅ'
      },
      {
        key: 'system_stats',
        value: JSON.stringify({ initialized_at: new Date().toISOString() }),
        description: 'Á≥ªÁªüÁªüËÆ°‰ø°ÊÅØ'
      }
    ]

    for (const config of systemConfigs) {
      const insertQuery = `
        INSERT INTO system_configs (key, value, description)
        VALUES ($1, $2, $3)
        ON CONFLICT (key) DO UPDATE SET
        value = EXCLUDED.value,
        updated_at = CURRENT_TIMESTAMP
      `

      await client.query(insertQuery, [config.key, config.value, config.description])
    }

    logger.info('‚úÖ ÂàùÂßãÊï∞ÊçÆÊèíÂÖ•ÂÆåÊàê')
  }

  async checkTableExists(tableName) {
    const client = await this.pool.connect()

    try {
      const result = await client.query(
        `
        SELECT EXISTS (
          SELECT FROM information_schema.tables
          WHERE table_schema = 'public'
          AND table_name = $1
        )
      `,
        [tableName]
      )

      return result.rows[0].exists
    } finally {
      client.release()
    }
  }

  async getTableInfo() {
    const client = await this.pool.connect()

    try {
      const result = await client.query(`
        SELECT
          t.table_name,
          t.table_type,
          c.column_count,
          i.index_count
        FROM information_schema.tables t
        LEFT JOIN (
          SELECT
            table_name,
            COUNT(*) as column_count
          FROM information_schema.columns
          WHERE table_schema = 'public'
          GROUP BY table_name
        ) c ON t.table_name = c.table_name
        LEFT JOIN (
          SELECT
            tablename,
            COUNT(*) as index_count
          FROM pg_indexes
          WHERE schemaname = 'public'
          GROUP BY tablename
        ) i ON t.table_name = i.tablename
        WHERE t.table_schema = 'public'
        AND t.table_type = 'BASE TABLE'
        ORDER BY t.table_name
      `)

      return result.rows
    } finally {
      client.release()
    }
  }

  async generateReport() {
    logger.info('üìä ÁîüÊàêÊï∞ÊçÆÂ∫ìÊä•Âëä...')

    const tableInfo = await this.getTableInfo()
    const client = await this.pool.connect()

    try {
      const report = {
        summary: {
          totalTables: tableInfo.length,
          totalColumns: tableInfo.reduce((sum, table) => sum + (table.column_count || 0), 0),
          totalIndexes: tableInfo.reduce((sum, table) => sum + (table.index_count || 0), 0),
          createdAt: new Date().toISOString()
        },
        tables: {}
      }

      // Ëé∑ÂèñÊØè‰∏™Ë°®ÁöÑËØ¶ÁªÜ‰ø°ÊÅØ
      for (const table of tableInfo) {
        const tableName = table.table_name

        // Ëé∑ÂèñË°åÊï∞
        const countResult = await client.query(`SELECT COUNT(*) as count FROM ${tableName}`)
        const rowCount = parseInt(countResult.rows[0].count)

        report.tables[tableName] = {
          columns: table.column_count || 0,
          indexes: table.index_count || 0,
          rows: rowCount,
          description: this.tables[tableName]?.description || 'Êú™Áü•Ë°®'
        }
      }

      // ‰øùÂ≠òÊä•Âëä
      const reportPath = path.join(__dirname, '../logs/database-report.json')
      require('fs').writeFileSync(reportPath, JSON.stringify(report, null, 2))

      logger.info('üìã Êï∞ÊçÆÂ∫ìÂàùÂßãÂåñÊä•Âëä:')
      logger.info(`   Ë°®Êï∞Èáè: ${report.summary.totalTables}`)
      logger.info(`   Â≠óÊÆµÊï∞Èáè: ${report.summary.totalColumns}`)
      logger.info(`   Á¥¢ÂºïÊï∞Èáè: ${report.summary.totalIndexes}`)
      logger.info(`   ËØ¶ÁªÜÊä•Âëä: ${reportPath}`)

      return report
    } finally {
      client.release()
    }
  }

  async cleanup() {
    if (this.pool) {
      await this.pool.end()
      logger.info('‚úÖ Êï∞ÊçÆÂ∫ìËøûÊé•Â∑≤ÂÖ≥Èó≠')
    }
  }
}

// CLIÂÖ•Âè£
async function main() {
  const initializer = new DatabaseInitializer()

  try {
    await initializer.initialize()

    // Ê£ÄÊü•ÊòØÂê¶Âº∫Âà∂ÈáçÊñ∞ÂàõÂª∫
    const forceRecreate = process.argv.includes('--force')

    if (forceRecreate) {
      logger.warn('‚ö†Ô∏è Âº∫Âà∂ÈáçÊñ∞ÂàõÂª∫Ê®°ÂºèÔºåÂ∞ÜÂà†Èô§Áé∞ÊúâË°®')
      // ËøôÈáåÂèØ‰ª•Ê∑ªÂä†Âà†Èô§Áé∞ÊúâË°®ÁöÑÈÄªËæë
    }

    // ÂàõÂª∫Êï∞ÊçÆÂ∫ìÁªìÊûÑ
    await initializer.createDatabase()

    // ÁîüÊàêÊä•Âëä
    await initializer.generateReport()

    logger.info('üéâ Êï∞ÊçÆÂ∫ìÂàùÂßãÂåñÊàêÂäüÂÆåÊàêÔºÅ')
  } catch (error) {
    logger.error(`‚ùå Êï∞ÊçÆÂ∫ìÂàùÂßãÂåñÂ§±Ë¥•: ${error.message}`)
    console.error('ËØ¶ÁªÜÈîôËØØ:', error)
    process.exit(1)
  } finally {
    await initializer.cleanup()
  }
}

// Â¶ÇÊûúÁõ¥Êé•ËøêË°åÊ≠§ËÑöÊú¨
if (require.main === module) {
  main().catch(console.error)
}

module.exports = DatabaseInitializer
