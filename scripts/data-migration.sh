#!/bin/bash

# =================================================================
# Claude Relay Service - æ•°æ®è¿ç§»å’Œå¤‡ä»½è„šæœ¬
# =================================================================
#
# åŠŸèƒ½ç‰¹æ€§ï¼š
# - Redis åˆ° PostgreSQL æ•°æ®è¿ç§»
# - PostgreSQL åˆ° Redis æ•°æ®è¿ç§»
# - å¢é‡æ•°æ®åŒæ­¥
# - æ•°æ®ä¸€è‡´æ€§éªŒè¯
# - è‡ªåŠ¨å¤‡ä»½å’Œæ¢å¤
# - è¿ç§»è¿›åº¦è·Ÿè¸ª
# - å›æ»šæ”¯æŒ
# - æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
#
# ä½¿ç”¨æ–¹æ³•ï¼š
#   ./scripts/data-migration.sh [OPTIONS] COMMAND
#
# å‘½ä»¤ï¼š
#   backup       : å¤‡ä»½æ•°æ®
#   restore      : æ¢å¤æ•°æ®
#   migrate      : è¿ç§»æ•°æ®
#   sync         : åŒæ­¥æ•°æ®
#   validate     : éªŒè¯æ•°æ®ä¸€è‡´æ€§
#   cleanup      : æ¸…ç†å¤‡ä»½æ–‡ä»¶
#   status       : æ˜¾ç¤ºè¿ç§»çŠ¶æ€
#
# é€‰é¡¹ï¼š
#   --source TYPE        : æºæ•°æ®åº“ç±»å‹ï¼ˆredis|postgresï¼‰
#   --target TYPE        : ç›®æ ‡æ•°æ®åº“ç±»å‹ï¼ˆpostgres|redisï¼‰
#   --backup-dir DIR     : å¤‡ä»½ç›®å½•ï¼ˆé»˜è®¤ï¼š./backupsï¼‰
#   --backup-file FILE   : æŒ‡å®šå¤‡ä»½æ–‡ä»¶
#   --strategy STRATEGY  : è¿ç§»ç­–ç•¥ï¼ˆfull|incrementalï¼‰
#   --batch-size SIZE    : æ‰¹å¤„ç†å¤§å°ï¼ˆé»˜è®¤ï¼š1000ï¼‰
#   --verify             : è¿ç§»åéªŒè¯æ•°æ®
#   --no-backup          : è·³è¿‡å¤‡ä»½
#   --force              : å¼ºåˆ¶æ‰§è¡Œï¼Œè·³è¿‡ç¡®è®¤
#   --dry-run            : æ¨¡æ‹Ÿè¿è¡Œ
#   --verbose            : æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
#   --help               : æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
#
# ç¤ºä¾‹ï¼š
#   ./scripts/data-migration.sh backup
#   ./scripts/data-migration.sh migrate --source redis --target postgres
#   ./scripts/data-migration.sh sync --strategy incremental
#   ./scripts/data-migration.sh restore --backup-file backup_20240916.tar.gz
#

set -euo pipefail

# =================================================================
# å…¨å±€å˜é‡å’Œé…ç½®
# =================================================================

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
cd "$PROJECT_ROOT"

# é»˜è®¤é…ç½®
DEFAULT_BACKUP_DIR="./backups"
DEFAULT_BATCH_SIZE=1000
DEFAULT_STRATEGY="full"

# è¿è¡Œæ—¶å˜é‡
COMMAND=""
SOURCE_DB=""
TARGET_DB=""
BACKUP_DIR="$DEFAULT_BACKUP_DIR"
BACKUP_FILE=""
MIGRATION_STRATEGY="$DEFAULT_STRATEGY"
BATCH_SIZE="$DEFAULT_BATCH_SIZE"
VERIFY_DATA=false
NO_BACKUP=false
FORCE_EXECUTE=false
DRY_RUN=false
VERBOSE=false
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")

# é¢œè‰²è¾“å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
WHITE='\033[1;37m'
GRAY='\033[0;37m'
NC='\033[0m' # No Color

# çŠ¶æ€å›¾æ ‡
ICON_SUCCESS="âœ…"
ICON_WARNING="âš ï¸"
ICON_ERROR="âŒ"
ICON_INFO="â„¹ï¸"
ICON_PROGRESS="ğŸ”„"

# ä¸´æ—¶æ–‡ä»¶
TEMP_DIR="/tmp/claude-relay-migration-$$"
MIGRATION_LOG="$TEMP_DIR/migration.log"
PROGRESS_FILE="$TEMP_DIR/progress.txt"

# =================================================================
# å·¥å…·å‡½æ•°
# =================================================================

log() {
    local level="$1"
    shift
    local message="$*"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")

    case "$level" in
        "ERROR")   echo -e "${RED}[ERROR]${NC} [$timestamp] $message" | tee -a "$MIGRATION_LOG" >&2 ;;
        "WARN")    echo -e "${YELLOW}[WARN]${NC}  [$timestamp] $message" | tee -a "$MIGRATION_LOG" >&2 ;;
        "INFO")    echo -e "${GREEN}[INFO]${NC}  [$timestamp] $message" | tee -a "$MIGRATION_LOG" ;;
        "DEBUG")   [[ "$VERBOSE" == true ]] && echo -e "${BLUE}[DEBUG]${NC} [$timestamp] $message" | tee -a "$MIGRATION_LOG" ;;
        "PROGRESS") echo -e "${CYAN}[PROGRESS]${NC} [$timestamp] $message" | tee -a "$MIGRATION_LOG" ;;
        *)         echo "[$timestamp] $message" | tee -a "$MIGRATION_LOG" ;;
    esac
}

print_header() {
    local title="$1"
    local width=80
    local padding=$(( (width - ${#title} - 2) / 2 ))

    echo ""
    echo -e "${CYAN}$(printf '=%.0s' $(seq 1 $width))${NC}"
    echo -e "${CYAN}$(printf '%*s' $padding)${WHITE} $title ${CYAN}$(printf '%*s' $padding)${NC}"
    echo -e "${CYAN}$(printf '=%.0s' $(seq 1 $width))${NC}"
    echo ""
}

show_progress() {
    local current="$1"
    local total="$2"
    local desc="$3"
    local percentage=$((current * 100 / total))
    local width=50
    local filled=$((current * width / total))
    local empty=$((width - filled))

    printf "\r${CYAN}Progress:${NC} ["
    printf "%*s" $filled | tr ' ' '='
    printf "%*s" $empty | tr ' ' '-'
    printf "] %d%% (%d/%d) %s" "$percentage" "$current" "$total" "$desc"

    echo "$current/$total $desc" > "$PROGRESS_FILE"

    if [[ $current -eq $total ]]; then
        echo ""
    fi
}

confirm() {
    local message="$1"
    local default="${2:-n}"

    if [[ "$FORCE_EXECUTE" == true ]]; then
        log "INFO" "Force mode enabled, auto-confirming: $message"
        return 0
    fi

    local prompt="$message (y/n) [${default}]: "
    read -p "$prompt" -r response
    response=${response:-$default}

    case "$response" in
        [yY]|[yY][eE][sS]) return 0 ;;
        *) return 1 ;;
    esac
}

setup_temp_directory() {
    mkdir -p "$TEMP_DIR"
    mkdir -p "$BACKUP_DIR"
    touch "$MIGRATION_LOG"
    touch "$PROGRESS_FILE"
}

cleanup_temp_directory() {
    if [[ -d "$TEMP_DIR" ]]; then
        rm -rf "$TEMP_DIR"
    fi
}

check_requirements() {
    log "INFO" "æ£€æŸ¥ç³»ç»Ÿè¦æ±‚..."

    local required_commands=("docker" "docker-compose" "jq" "node")
    local missing_commands=()

    for cmd in "${required_commands[@]}"; do
        if ! command -v "$cmd" &> /dev/null; then
            missing_commands+=("$cmd")
        fi
    done

    if [[ ${#missing_commands[@]} -gt 0 ]]; then
        log "ERROR" "ç¼ºå°‘å¿…è¦çš„å‘½ä»¤: ${missing_commands[*]}"
        exit 1
    fi

    # æ£€æŸ¥ Docker æœåŠ¡
    if ! docker info &> /dev/null; then
        log "ERROR" "Docker æœåŠ¡æœªè¿è¡Œ"
        exit 1
    fi

    # æ£€æŸ¥æ•°æ®åº“ç®¡ç†è„šæœ¬
    if [[ ! -f "scripts/database-manager.js" ]]; then
        log "ERROR" "æ•°æ®åº“ç®¡ç†è„šæœ¬ä¸å­˜åœ¨: scripts/database-manager.js"
        exit 1
    fi

    log "INFO" "ç³»ç»Ÿè¦æ±‚æ£€æŸ¥é€šè¿‡"
}

check_database_connections() {
    log "INFO" "æ£€æŸ¥æ•°æ®åº“è¿æ¥..."

    # æ£€æŸ¥ Redis è¿æ¥
    if docker ps --format "table {{.Names}}" | grep -q "claude-relay-redis"; then
        if docker exec claude-relay-redis redis-cli ping > /dev/null 2>&1; then
            log "INFO" "Redis è¿æ¥æ­£å¸¸"
        else
            log "ERROR" "Redis è¿æ¥å¤±è´¥"
            exit 1
        fi
    else
        log "WARN" "Redis å®¹å™¨æœªè¿è¡Œ"
    fi

    # æ£€æŸ¥ PostgreSQL è¿æ¥
    if docker ps --format "table {{.Names}}" | grep -q "claude-relay-postgres"; then
        if docker exec claude-relay-postgres pg_isready -U "${POSTGRES_USER:-postgres}" > /dev/null 2>&1; then
            log "INFO" "PostgreSQL è¿æ¥æ­£å¸¸"
        else
            log "ERROR" "PostgreSQL è¿æ¥å¤±è´¥"
            exit 1
        fi
    else
        log "WARN" "PostgreSQL å®¹å™¨æœªè¿è¡Œ"
    fi
}

# =================================================================
# å¤‡ä»½å’Œæ¢å¤åŠŸèƒ½
# =================================================================

cmd_backup() {
    print_header "æ•°æ®å¤‡ä»½"

    local backup_name="backup_${TIMESTAMP}"
    local backup_archive="${BACKUP_DIR}/${backup_name}.tar.gz"

    if [[ -n "$BACKUP_FILE" ]]; then
        backup_archive="$BACKUP_FILE"
        backup_name=$(basename "$backup_archive" .tar.gz)
    fi

    log "INFO" "å¼€å§‹æ•°æ®å¤‡ä»½: $backup_name"

    if [[ "$DRY_RUN" == true ]]; then
        log "INFO" "[DRY RUN] å°†åˆ›å»ºå¤‡ä»½: $backup_archive"
        return 0
    fi

    local temp_backup_dir="$TEMP_DIR/backup"
    mkdir -p "$temp_backup_dir"

    # å¤‡ä»½åº”ç”¨æ•°æ®
    if [[ -d "./data" ]]; then
        log "INFO" "å¤‡ä»½åº”ç”¨æ•°æ®ç›®å½•..."
        cp -r ./data "$temp_backup_dir/" 2>/dev/null || true
    fi

    # å¤‡ä»½é…ç½®æ–‡ä»¶
    if [[ -d "./config" ]]; then
        log "INFO" "å¤‡ä»½é…ç½®æ–‡ä»¶..."
        cp -r ./config "$temp_backup_dir/" 2>/dev/null || true
    fi

    # å¤‡ä»½ç¯å¢ƒé…ç½®
    if [[ -f ".env" ]]; then
        cp .env "$temp_backup_dir/" 2>/dev/null || true
    fi

    # å¯¼å‡º Redis æ•°æ®
    if docker ps --format "table {{.Names}}" | grep -q "claude-relay-redis"; then
        log "INFO" "å¯¼å‡º Redis æ•°æ®..."

        # è§¦å‘ Redis ä¿å­˜
        docker exec claude-relay-redis redis-cli BGSAVE > /dev/null 2>&1 || true
        sleep 5

        # å¯¼å‡º RDB æ–‡ä»¶
        docker cp claude-relay-redis:/data/dump.rdb "$temp_backup_dir/redis.rdb" 2>/dev/null || true

        # å¯¼å‡º Redis æ•°æ®ä¸º JSON
        local redis_export="$temp_backup_dir/redis_data.json"
        if timeout 60 node scripts/database-manager.js export-redis > "$redis_export" 2>/dev/null; then
            log "INFO" "Redis æ•°æ®å¯¼å‡ºå®Œæˆ"
        else
            log "WARN" "Redis æ•°æ®å¯¼å‡ºå¤±è´¥ï¼Œä½¿ç”¨ RDB æ–‡ä»¶"
        fi
    fi

    # å¯¼å‡º PostgreSQL æ•°æ®
    if docker ps --format "table {{.Names}}" | grep -q "claude-relay-postgres"; then
        log "INFO" "å¯¼å‡º PostgreSQL æ•°æ®..."

        local pg_dump_file="$temp_backup_dir/postgres.sql"
        if docker exec claude-relay-postgres pg_dump -U "${POSTGRES_USER:-postgres}" "${POSTGRES_DATABASE:-claude_relay}" > "$pg_dump_file" 2>/dev/null; then
            log "INFO" "PostgreSQL æ•°æ®å¯¼å‡ºå®Œæˆ"
        else
            log "WARN" "PostgreSQL æ•°æ®å¯¼å‡ºå¤±è´¥"
        fi

        # å¯¼å‡º PostgreSQL æ•°æ®ä¸º JSON
        local pg_export="$temp_backup_dir/postgres_data.json"
        if timeout 60 node scripts/database-manager.js export-postgres > "$pg_export" 2>/dev/null; then
            log "INFO" "PostgreSQL æ•°æ®å¯¼å‡ºå®Œæˆ"
        else
            log "WARN" "PostgreSQL æ•°æ®å¯¼å‡ºå¤±è´¥"
        fi
    fi

    # åˆ›å»ºå¤‡ä»½å…ƒæ•°æ®
    cat > "$temp_backup_dir/metadata.json" << EOF
{
  "backup_name": "$backup_name",
  "timestamp": "$TIMESTAMP",
  "created_at": "$(date -Iseconds)",
  "version": "$(cat package.json | jq -r .version 2>/dev/null || echo 'unknown')",
  "strategy": "full",
  "source": "mixed",
  "includes": {
    "application_data": $([ -d "./data" ] && echo "true" || echo "false"),
    "configuration": $([ -d "./config" ] && echo "true" || echo "false"),
    "redis_data": $(docker ps --format "table {{.Names}}" | grep -q "claude-relay-redis" && echo "true" || echo "false"),
    "postgres_data": $(docker ps --format "table {{.Names}}" | grep -q "claude-relay-postgres" && echo "true" || echo "false")
  }
}
EOF

    # åˆ›å»ºå¤‡ä»½å­˜æ¡£
    log "INFO" "åˆ›å»ºå¤‡ä»½å­˜æ¡£..."
    (cd "$temp_backup_dir" && tar -czf "$backup_archive" .) || {
        log "ERROR" "å¤‡ä»½å­˜æ¡£åˆ›å»ºå¤±è´¥"
        exit 1
    }

    local backup_size=$(du -h "$backup_archive" | cut -f1)
    log "INFO" "å¤‡ä»½å®Œæˆ: $backup_archive (å¤§å°: $backup_size)"

    # æ¸…ç†è¶…è¿‡ 10 ä¸ªçš„æ—§å¤‡ä»½
    log "INFO" "æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶..."
    find "$BACKUP_DIR" -name "backup_*.tar.gz" -type f | sort -r | tail -n +11 | xargs rm -f 2>/dev/null || true
}

cmd_restore() {
    print_header "æ•°æ®æ¢å¤"

    if [[ -z "$BACKUP_FILE" ]]; then
        # é€‰æ‹©æœ€æ–°çš„å¤‡ä»½æ–‡ä»¶
        BACKUP_FILE=$(find "$BACKUP_DIR" -name "backup_*.tar.gz" -type f | sort -r | head -1)
        if [[ -z "$BACKUP_FILE" ]]; then
            log "ERROR" "æœªæ‰¾åˆ°å¤‡ä»½æ–‡ä»¶"
            exit 1
        fi
        log "INFO" "ä½¿ç”¨æœ€æ–°å¤‡ä»½æ–‡ä»¶: $BACKUP_FILE"
    fi

    if [[ ! -f "$BACKUP_FILE" ]]; then
        log "ERROR" "å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: $BACKUP_FILE"
        exit 1
    fi

    log "INFO" "å¼€å§‹æ•°æ®æ¢å¤: $BACKUP_FILE"

    if ! confirm "ç¡®è®¤æ¢å¤æ•°æ®ï¼Ÿè¿™å°†è¦†ç›–ç°æœ‰æ•°æ®"; then
        log "INFO" "ç”¨æˆ·å–æ¶ˆæ¢å¤æ“ä½œ"
        return 0
    fi

    if [[ "$DRY_RUN" == true ]]; then
        log "INFO" "[DRY RUN] å°†æ¢å¤å¤‡ä»½: $BACKUP_FILE"
        return 0
    fi

    local restore_dir="$TEMP_DIR/restore"
    mkdir -p "$restore_dir"

    # è§£å‹å¤‡ä»½æ–‡ä»¶
    log "INFO" "è§£å‹å¤‡ä»½æ–‡ä»¶..."
    tar -xzf "$BACKUP_FILE" -C "$restore_dir" || {
        log "ERROR" "å¤‡ä»½æ–‡ä»¶è§£å‹å¤±è´¥"
        exit 1
    }

    # æ£€æŸ¥å¤‡ä»½å…ƒæ•°æ®
    if [[ -f "$restore_dir/metadata.json" ]]; then
        log "INFO" "å¤‡ä»½ä¿¡æ¯:"
        local backup_name=$(jq -r .backup_name "$restore_dir/metadata.json" 2>/dev/null || echo "unknown")
        local created_at=$(jq -r .created_at "$restore_dir/metadata.json" 2>/dev/null || echo "unknown")
        log "INFO" "  å¤‡ä»½åç§°: $backup_name"
        log "INFO" "  åˆ›å»ºæ—¶é—´: $created_at"
    fi

    # åœæ­¢æœåŠ¡
    log "INFO" "åœæ­¢åº”ç”¨æœåŠ¡..."
    docker-compose stop claude-relay 2>/dev/null || true

    # æ¢å¤åº”ç”¨æ•°æ®
    if [[ -d "$restore_dir/data" ]]; then
        log "INFO" "æ¢å¤åº”ç”¨æ•°æ®..."
        rm -rf ./data 2>/dev/null || true
        cp -r "$restore_dir/data" ./ 2>/dev/null || true
    fi

    # æ¢å¤é…ç½®æ–‡ä»¶
    if [[ -d "$restore_dir/config" ]]; then
        log "INFO" "æ¢å¤é…ç½®æ–‡ä»¶..."
        cp -r "$restore_dir/config"/* ./config/ 2>/dev/null || true
    fi

    # æ¢å¤ç¯å¢ƒé…ç½®
    if [[ -f "$restore_dir/.env" ]]; then
        log "INFO" "æ¢å¤ç¯å¢ƒé…ç½®..."
        cp "$restore_dir/.env" ./ 2>/dev/null || true
    fi

    # æ¢å¤ Redis æ•°æ®
    if [[ -f "$restore_dir/redis.rdb" ]] && docker ps --format "table {{.Names}}" | grep -q "claude-relay-redis"; then
        log "INFO" "æ¢å¤ Redis æ•°æ®..."

        docker exec claude-relay-redis redis-cli FLUSHALL > /dev/null 2>&1 || true
        docker cp "$restore_dir/redis.rdb" claude-relay-redis:/data/dump.rdb 2>/dev/null || true
        docker restart claude-relay-redis > /dev/null 2>&1 || true
        sleep 10
    fi

    # æ¢å¤ PostgreSQL æ•°æ®
    if [[ -f "$restore_dir/postgres.sql" ]] && docker ps --format "table {{.Names}}" | grep -q "claude-relay-postgres"; then
        log "INFO" "æ¢å¤ PostgreSQL æ•°æ®..."

        docker exec claude-relay-postgres psql -U "${POSTGRES_USER:-postgres}" -d "${POSTGRES_DATABASE:-claude_relay}" -c "DROP SCHEMA public CASCADE; CREATE SCHEMA public;" > /dev/null 2>&1 || true
        docker exec -i claude-relay-postgres psql -U "${POSTGRES_USER:-postgres}" -d "${POSTGRES_DATABASE:-claude_relay}" < "$restore_dir/postgres.sql" > /dev/null 2>&1 || true
    fi

    # é‡å¯æœåŠ¡
    log "INFO" "é‡å¯åº”ç”¨æœåŠ¡..."
    docker-compose start claude-relay 2>/dev/null || true

    log "INFO" "æ•°æ®æ¢å¤å®Œæˆ"
}

# =================================================================
# æ•°æ®è¿ç§»åŠŸèƒ½
# =================================================================

cmd_migrate() {
    print_header "æ•°æ®è¿ç§»"

    if [[ -z "$SOURCE_DB" ]] || [[ -z "$TARGET_DB" ]]; then
        log "ERROR" "å¿…é¡»æŒ‡å®šæºæ•°æ®åº“å’Œç›®æ ‡æ•°æ®åº“"
        log "ERROR" "ä½¿ç”¨ --source å’Œ --target å‚æ•°"
        exit 1
    fi

    log "INFO" "è¿ç§»é…ç½®:"
    log "INFO" "  æºæ•°æ®åº“: $SOURCE_DB"
    log "INFO" "  ç›®æ ‡æ•°æ®åº“: $TARGET_DB"
    log "INFO" "  è¿ç§»ç­–ç•¥: $MIGRATION_STRATEGY"
    log "INFO" "  æ‰¹å¤„ç†å¤§å°: $BATCH_SIZE"

    if ! confirm "ç¡®è®¤å¼€å§‹æ•°æ®è¿ç§»ï¼Ÿ"; then
        log "INFO" "ç”¨æˆ·å–æ¶ˆè¿ç§»æ“ä½œ"
        return 0
    fi

    if [[ "$DRY_RUN" == true ]]; then
        log "INFO" "[DRY RUN] å°†æ‰§è¡Œæ•°æ®è¿ç§»"
        return 0
    fi

    # æ‰§è¡Œè¿ç§»å‰å¤‡ä»½
    if [[ "$NO_BACKUP" == false ]]; then
        log "INFO" "æ‰§è¡Œè¿ç§»å‰å¤‡ä»½..."
        BACKUP_FILE="${BACKUP_DIR}/pre_migration_${TIMESTAMP}.tar.gz"
        cmd_backup
    fi

    # æ ¹æ®è¿ç§»æ–¹å‘æ‰§è¡Œè¿ç§»
    case "${SOURCE_DB}_to_${TARGET_DB}" in
        "redis_to_postgres")
            migrate_redis_to_postgres
            ;;
        "postgres_to_redis")
            migrate_postgres_to_redis
            ;;
        *)
            log "ERROR" "ä¸æ”¯æŒçš„è¿ç§»è·¯å¾„: $SOURCE_DB -> $TARGET_DB"
            exit 1
            ;;
    esac

    # æ•°æ®éªŒè¯
    if [[ "$VERIFY_DATA" == true ]]; then
        log "INFO" "éªŒè¯è¿ç§»åçš„æ•°æ®..."
        cmd_validate
    fi

    log "INFO" "æ•°æ®è¿ç§»å®Œæˆ"
}

migrate_redis_to_postgres() {
    log "INFO" "å¼€å§‹ Redis åˆ° PostgreSQL è¿ç§»..."

    # ä½¿ç”¨æ•°æ®åº“ç®¡ç†å™¨è¿›è¡Œè¿ç§»
    if timeout 300 node scripts/database-manager.js sync --source redis --target postgres --force; then
        log "INFO" "Redis åˆ° PostgreSQL è¿ç§»æˆåŠŸ"
    else
        log "ERROR" "Redis åˆ° PostgreSQL è¿ç§»å¤±è´¥"
        exit 1
    fi
}

migrate_postgres_to_redis() {
    log "INFO" "å¼€å§‹ PostgreSQL åˆ° Redis è¿ç§»..."

    # ä½¿ç”¨æ•°æ®åº“ç®¡ç†å™¨è¿›è¡Œè¿ç§»
    if timeout 300 node scripts/database-manager.js sync --source postgres --target redis --force; then
        log "INFO" "PostgreSQL åˆ° Redis è¿ç§»æˆåŠŸ"
    else
        log "ERROR" "PostgreSQL åˆ° Redis è¿ç§»å¤±è´¥"
        exit 1
    fi
}

# =================================================================
# æ•°æ®åŒæ­¥å’ŒéªŒè¯åŠŸèƒ½
# =================================================================

cmd_sync() {
    print_header "æ•°æ®åŒæ­¥"

    log "INFO" "æ‰§è¡Œæ•°æ®åŒæ­¥ï¼ˆç­–ç•¥: $MIGRATION_STRATEGYï¼‰..."

    if [[ "$DRY_RUN" == true ]]; then
        log "INFO" "[DRY RUN] å°†æ‰§è¡Œæ•°æ®åŒæ­¥"
        return 0
    fi

    case "$MIGRATION_STRATEGY" in
        "full")
            log "INFO" "æ‰§è¡Œå…¨é‡åŒæ­¥..."
            if timeout 300 node scripts/database-manager.js sync --force; then
                log "INFO" "å…¨é‡åŒæ­¥å®Œæˆ"
            else
                log "ERROR" "å…¨é‡åŒæ­¥å¤±è´¥"
                exit 1
            fi
            ;;
        "incremental")
            log "INFO" "æ‰§è¡Œå¢é‡åŒæ­¥..."
            # å¢é‡åŒæ­¥é€»è¾‘éœ€è¦æ ¹æ®å…·ä½“å®ç°è°ƒæ•´
            log "WARN" "å¢é‡åŒæ­¥åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­"
            ;;
        *)
            log "ERROR" "æœªçŸ¥çš„åŒæ­¥ç­–ç•¥: $MIGRATION_STRATEGY"
            exit 1
            ;;
    esac
}

cmd_validate() {
    print_header "æ•°æ®ä¸€è‡´æ€§éªŒè¯"

    log "INFO" "å¼€å§‹æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥..."

    if [[ "$DRY_RUN" == true ]]; then
        log "INFO" "[DRY RUN] å°†æ‰§è¡Œæ•°æ®éªŒè¯"
        return 0
    fi

    # ä½¿ç”¨æ•°æ®åº“ç®¡ç†å™¨æ£€æŸ¥ä¸€è‡´æ€§
    if timeout 120 node scripts/database-manager.js check-consistency; then
        log "INFO" "æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡"
    else
        log "WARN" "æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å‘ç°é—®é¢˜"
        return 1
    fi
}

# =================================================================
# çŠ¶æ€å’Œæ¸…ç†åŠŸèƒ½
# =================================================================

cmd_status() {
    print_header "è¿ç§»çŠ¶æ€"

    # æ£€æŸ¥å¤‡ä»½æ–‡ä»¶
    log "INFO" "å¤‡ä»½æ–‡ä»¶çŠ¶æ€:"
    if [[ -d "$BACKUP_DIR" ]]; then
        local backup_count=$(find "$BACKUP_DIR" -name "backup_*.tar.gz" -type f | wc -l)
        log "INFO" "  å¤‡ä»½æ–‡ä»¶æ•°é‡: $backup_count"

        if [[ $backup_count -gt 0 ]]; then
            local latest_backup=$(find "$BACKUP_DIR" -name "backup_*.tar.gz" -type f | sort -r | head -1)
            local backup_size=$(du -h "$latest_backup" | cut -f1)
            local backup_date=$(stat -c %y "$latest_backup" 2>/dev/null | cut -d' ' -f1 || echo "unknown")
            log "INFO" "  æœ€æ–°å¤‡ä»½: $(basename "$latest_backup")"
            log "INFO" "  å¤‡ä»½å¤§å°: $backup_size"
            log "INFO" "  å¤‡ä»½æ—¥æœŸ: $backup_date"
        fi
    else
        log "INFO" "  å¤‡ä»½ç›®å½•ä¸å­˜åœ¨"
    fi

    # æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
    log "INFO" "æ•°æ®åº“çŠ¶æ€:"
    if timeout 30 node scripts/database-manager.js health > /dev/null 2>&1; then
        log "INFO" "  æ•°æ®åº“å¥åº·çŠ¶æ€: æ­£å¸¸"
    else
        log "WARN" "  æ•°æ®åº“å¥åº·çŠ¶æ€: å¼‚å¸¸"
    fi

    # æ£€æŸ¥è¿ç§»è¿›åº¦
    if [[ -f "$PROGRESS_FILE" ]]; then
        local progress=$(cat "$PROGRESS_FILE")
        log "INFO" "  å½“å‰è¿ç§»è¿›åº¦: $progress"
    fi
}

cmd_cleanup() {
    print_header "æ¸…ç†å¤‡ä»½æ–‡ä»¶"

    if [[ ! -d "$BACKUP_DIR" ]]; then
        log "INFO" "å¤‡ä»½ç›®å½•ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†"
        return 0
    fi

    local backup_files=($(find "$BACKUP_DIR" -name "backup_*.tar.gz" -type f | sort))
    local backup_count=${#backup_files[@]}

    if [[ $backup_count -eq 0 ]]; then
        log "INFO" "æ²¡æœ‰æ‰¾åˆ°å¤‡ä»½æ–‡ä»¶"
        return 0
    fi

    log "INFO" "æ‰¾åˆ° $backup_count ä¸ªå¤‡ä»½æ–‡ä»¶"

    # ä¿ç•™æœ€è¿‘ 5 ä¸ªå¤‡ä»½ï¼Œåˆ é™¤å…¶ä½™çš„
    local keep_count=5
    if [[ $backup_count -gt $keep_count ]]; then
        local delete_count=$((backup_count - keep_count))
        log "INFO" "å°†åˆ é™¤ $delete_count ä¸ªæ—§å¤‡ä»½æ–‡ä»¶"

        if confirm "ç¡®è®¤åˆ é™¤æ—§å¤‡ä»½æ–‡ä»¶ï¼Ÿ"; then
            if [[ "$DRY_RUN" == false ]]; then
                for ((i=0; i<delete_count; i++)); do
                    local file_to_delete="${backup_files[$i]}"
                    rm -f "$file_to_delete"
                    log "INFO" "å·²åˆ é™¤: $(basename "$file_to_delete")"
                done
            else
                log "INFO" "[DRY RUN] å°†åˆ é™¤ $delete_count ä¸ªæ–‡ä»¶"
            fi
        else
            log "INFO" "ç”¨æˆ·å–æ¶ˆæ¸…ç†æ“ä½œ"
        fi
    else
        log "INFO" "å¤‡ä»½æ–‡ä»¶æ•°é‡æœªè¶…è¿‡ä¿ç•™é™åˆ¶ï¼Œæ— éœ€æ¸…ç†"
    fi
}

# =================================================================
# å¸®åŠ©å’Œå‚æ•°è§£æ
# =================================================================

show_help() {
    cat << EOF
Claude Relay Service - æ•°æ®è¿ç§»å’Œå¤‡ä»½è„šæœ¬

ä½¿ç”¨æ–¹æ³•:
  $0 [OPTIONS] COMMAND

å‘½ä»¤:
  backup       å¤‡ä»½æ•°æ®
  restore      æ¢å¤æ•°æ®
  migrate      è¿ç§»æ•°æ®
  sync         åŒæ­¥æ•°æ®
  validate     éªŒè¯æ•°æ®ä¸€è‡´æ€§
  cleanup      æ¸…ç†å¤‡ä»½æ–‡ä»¶
  status       æ˜¾ç¤ºè¿ç§»çŠ¶æ€

é€‰é¡¹:
  --source TYPE         æºæ•°æ®åº“ç±»å‹ï¼ˆredis|postgresï¼‰
  --target TYPE         ç›®æ ‡æ•°æ®åº“ç±»å‹ï¼ˆpostgres|redisï¼‰
  --backup-dir DIR      å¤‡ä»½ç›®å½•ï¼ˆé»˜è®¤ï¼š./backupsï¼‰
  --backup-file FILE    æŒ‡å®šå¤‡ä»½æ–‡ä»¶
  --strategy STRATEGY   è¿ç§»ç­–ç•¥ï¼ˆfull|incrementalï¼‰
  --batch-size SIZE     æ‰¹å¤„ç†å¤§å°ï¼ˆé»˜è®¤ï¼š1000ï¼‰
  --verify              è¿ç§»åéªŒè¯æ•°æ®
  --no-backup           è·³è¿‡å¤‡ä»½
  --force               å¼ºåˆ¶æ‰§è¡Œï¼Œè·³è¿‡ç¡®è®¤
  --dry-run             æ¨¡æ‹Ÿè¿è¡Œ
  --verbose             æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
  --help                æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯

ç¤ºä¾‹:
  $0 backup
  $0 migrate --source redis --target postgres --verify
  $0 sync --strategy incremental
  $0 restore --backup-file backup_20240916.tar.gz
  $0 cleanup --dry-run

æ›´å¤šä¿¡æ¯è¯·å‚è€ƒé¡¹ç›®æ–‡æ¡£ã€‚
EOF
}

parse_arguments() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            --source)
                SOURCE_DB="$2"
                shift 2
                ;;
            --target)
                TARGET_DB="$2"
                shift 2
                ;;
            --backup-dir)
                BACKUP_DIR="$2"
                shift 2
                ;;
            --backup-file)
                BACKUP_FILE="$2"
                shift 2
                ;;
            --strategy)
                MIGRATION_STRATEGY="$2"
                shift 2
                ;;
            --batch-size)
                BATCH_SIZE="$2"
                shift 2
                ;;
            --verify)
                VERIFY_DATA=true
                shift
                ;;
            --no-backup)
                NO_BACKUP=true
                shift
                ;;
            --force)
                FORCE_EXECUTE=true
                shift
                ;;
            --dry-run)
                DRY_RUN=true
                shift
                ;;
            --verbose)
                VERBOSE=true
                shift
                ;;
            --help)
                show_help
                exit 0
                ;;
            backup|restore|migrate|sync|validate|cleanup|status)
                COMMAND="$1"
                shift
                ;;
            *)
                log "ERROR" "æœªçŸ¥å‚æ•°: $1"
                log "ERROR" "ä½¿ç”¨ --help æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯"
                exit 1
                ;;
        esac
    done

    if [[ -z "$COMMAND" ]]; then
        log "ERROR" "å¿…é¡»æŒ‡å®šå‘½ä»¤"
        log "ERROR" "ä½¿ç”¨ --help æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯"
        exit 1
    fi

    # éªŒè¯å‚æ•°
    if [[ "$COMMAND" == "migrate" ]]; then
        if [[ -z "$SOURCE_DB" ]] || [[ -z "$TARGET_DB" ]]; then
            log "ERROR" "migrate å‘½ä»¤å¿…é¡»æŒ‡å®š --source å’Œ --target å‚æ•°"
            exit 1
        fi

        local valid_dbs=("redis" "postgres")
        if [[ ! " ${valid_dbs[@]} " =~ " $SOURCE_DB " ]] || [[ ! " ${valid_dbs[@]} " =~ " $TARGET_DB " ]]; then
            log "ERROR" "æ•°æ®åº“ç±»å‹å¿…é¡»æ˜¯: ${valid_dbs[*]}"
            exit 1
        fi

        if [[ "$SOURCE_DB" == "$TARGET_DB" ]]; then
            log "ERROR" "æºæ•°æ®åº“å’Œç›®æ ‡æ•°æ®åº“ä¸èƒ½ç›¸åŒ"
            exit 1
        fi
    fi
}

# =================================================================
# ä¸»å‡½æ•°
# =================================================================

main() {
    parse_arguments "$@"

    print_header "Claude Relay Service æ•°æ®è¿ç§»å·¥å…·"

    if [[ "$DRY_RUN" == true ]]; then
        log "INFO" "è¿è¡Œæ¨¡å¼: DRY RUNï¼ˆæ¨¡æ‹Ÿæ‰§è¡Œï¼‰"
    fi

    # è®¾ç½®ä¸´æ—¶ç›®å½•
    setup_temp_directory

    # è®¾ç½®æ¸…ç†å‡½æ•°
    trap cleanup_temp_directory EXIT

    # æ£€æŸ¥è¦æ±‚
    check_requirements
    check_database_connections

    # åŠ è½½ç¯å¢ƒé…ç½®
    if [[ -f ".env" ]]; then
        source .env
    fi

    # æ‰§è¡Œå‘½ä»¤
    case "$COMMAND" in
        "backup")   cmd_backup ;;
        "restore")  cmd_restore ;;
        "migrate")  cmd_migrate ;;
        "sync")     cmd_sync ;;
        "validate") cmd_validate ;;
        "cleanup")  cmd_cleanup ;;
        "status")   cmd_status ;;
        *)
            log "ERROR" "æœªçŸ¥å‘½ä»¤: $COMMAND"
            exit 1
            ;;
    esac

    log "INFO" "æ“ä½œå®Œæˆ"
}

# =================================================================
# é”™è¯¯å¤„ç†å’Œè„šæœ¬å…¥å£
# =================================================================

trap 'log "ERROR" "è„šæœ¬æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯"; cleanup_temp_directory; exit 1' ERR

# ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•ä¸­è¿è¡Œ
if [[ ! -f "package.json" ]] || [[ ! -f "docker-compose.yml" ]]; then
    log "ERROR" "è¯·åœ¨ Claude Relay Service é¡¹ç›®æ ¹ç›®å½•ä¸­è¿è¡Œæ­¤è„šæœ¬"
    exit 1
fi

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"