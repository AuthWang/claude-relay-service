# PostgreSQL æ•´åˆæµ‹è¯•è®¡åˆ’

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æè¿° PostgreSQL æ•°æ®åº“æ•´åˆçš„å…¨é¢æµ‹è¯•ç­–ç•¥ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§ã€æ€§èƒ½è¾¾æ ‡å’Œæ•°æ®å®Œæ•´æ€§ã€‚

### ğŸ¯ æµ‹è¯•ç›®æ ‡

- **åŠŸèƒ½å®Œæ•´æ€§**ï¼šéªŒè¯æ‰€æœ‰åŠŸèƒ½åœ¨æ–°æ¶æ„ä¸‹æ­£å¸¸è¿è¡Œ
- **æ€§èƒ½åŸºå‡†**ï¼šç¡®ä¿æ€§èƒ½ä¸ä½äºç°æœ‰ Redis æ¶æ„
- **æ•°æ®ä¸€è‡´æ€§**ï¼šä¿è¯è¿ç§»è¿‡ç¨‹ä¸­æ•°æ®å®Œæ•´ä¸”ä¸€è‡´
- **æ•…éšœæ¢å¤**ï¼šéªŒè¯å¼‚å¸¸æƒ…å†µä¸‹çš„è‡ªåŠ¨æ¢å¤èƒ½åŠ›

## ğŸ§ª æµ‹è¯•ç­–ç•¥æ¦‚è§ˆ

### æµ‹è¯•é‡‘å­—å¡”
```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   E2E Tests     â”‚  â† 10% (å…³é”®ç”¨æˆ·åœºæ™¯)
    â”‚   (End-to-End)  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Integration     â”‚  â† 20% (API é›†æˆæµ‹è¯•)
    â”‚   Tests         â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚   Unit Tests    â”‚  â† 70% (æ•°æ®è®¿é—®å±‚)
    â”‚                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æµ‹è¯•åˆ†ç±»

1. **å•å…ƒæµ‹è¯•** - æ•°æ®è®¿é—®å±‚ã€æœåŠ¡å±‚é€»è¾‘
2. **é›†æˆæµ‹è¯•** - æ•°æ®åº“äº¤äº’ã€API ç«¯ç‚¹
3. **æ€§èƒ½æµ‹è¯•** - è´Ÿè½½æµ‹è¯•ã€å‹åŠ›æµ‹è¯•ã€åŸºå‡†æµ‹è¯•
4. **æ•°æ®è¿ç§»æµ‹è¯•** - è¿ç§»æ­£ç¡®æ€§ã€æ•°æ®å®Œæ•´æ€§
5. **å…¼å®¹æ€§æµ‹è¯•** - å‘åå…¼å®¹æ€§éªŒè¯
6. **æ•…éšœæµ‹è¯•** - é”™è¯¯å¤„ç†ã€æ¢å¤æœºåˆ¶

## ğŸ”¬ å•å…ƒæµ‹è¯•è®¡åˆ’

### 1. æ•°æ®è®¿é—®å±‚æµ‹è¯•

#### **PostgreSQL å®¢æˆ·ç«¯æµ‹è¯•**

**æµ‹è¯•æ–‡ä»¶ï¼š`tests/unit/models/postgres.test.js`**

```javascript
describe('PostgresClient', () => {
  let client;
  let mockPool;

  beforeEach(() => {
    mockPool = {
      query: jest.fn(),
      connect: jest.fn(),
      release: jest.fn()
    };
    client = new PostgresClient({ pool: mockPool });
  });

  describe('API Key Operations', () => {
    it('åº”è¯¥æ­£ç¡®åˆ›å»º API Key', async () => {
      const keyData = {
        name: 'Test Key',
        permissions: 'all',
        isActive: true
      };

      mockPool.query.mockResolvedValue({
        rows: [{ id: 'test-id', ...keyData }],
        rowCount: 1
      });

      const result = await client.createApiKey(keyData);

      expect(result.success).toBe(true);
      expect(result.data.id).toBe('test-id');
      expect(mockPool.query).toHaveBeenCalledWith(
        expect.stringContaining('INSERT INTO api_keys'),
        expect.arrayContaining([keyData.name, keyData.permissions])
      );
    });

    it('åº”è¯¥å¤„ç†é‡å¤é”®é”™è¯¯', async () => {
      mockPool.query.mockRejectedValue(
        new Error('duplicate key value violates unique constraint')
      );

      const result = await client.createApiKey({ name: 'Duplicate' });

      expect(result.success).toBe(false);
      expect(result.error).toContain('duplicate key');
    });

    it('åº”è¯¥æ­£ç¡®éªŒè¯ API Key', async () => {
      const hashedKey = 'hashed-key-value';
      mockPool.query.mockResolvedValue({
        rows: [{
          id: 'test-id',
          permissions: 'all',
          is_active: true,
          expires_at: null
        }],
        rowCount: 1
      });

      const result = await client.validateApiKey(hashedKey);

      expect(result.success).toBe(true);
      expect(result.data.permissions).toBe('all');
      expect(result.data.isActive).toBe(true);
    });
  });

  describe('Connection Management', () => {
    it('åº”è¯¥æ­£ç¡®ç®¡ç†è¿æ¥æ± ', async () => {
      mockPool.connect.mockResolvedValue({ query: jest.fn() });

      const connection = await client.getConnection();

      expect(mockPool.connect).toHaveBeenCalled();
      expect(connection).toBeDefined();
    });

    it('åº”è¯¥å¤„ç†è¿æ¥è¶…æ—¶', async () => {
      mockPool.connect.mockRejectedValue(new Error('connection timeout'));

      await expect(client.getConnection()).rejects.toThrow('connection timeout');
    });
  });

  describe('Transaction Management', () => {
    it('åº”è¯¥æ­£ç¡®æ‰§è¡Œäº‹åŠ¡', async () => {
      const mockClient = {
        query: jest.fn().mockResolvedValue({ rows: [] }),
        release: jest.fn()
      };
      mockPool.connect.mockResolvedValue(mockClient);

      await client.executeTransaction(async (tx) => {
        await tx.query('SELECT 1');
        await tx.query('SELECT 2');
      });

      expect(mockClient.query).toHaveBeenCalledWith('BEGIN');
      expect(mockClient.query).toHaveBeenCalledWith('SELECT 1');
      expect(mockClient.query).toHaveBeenCalledWith('SELECT 2');
      expect(mockClient.query).toHaveBeenCalledWith('COMMIT');
      expect(mockClient.release).toHaveBeenCalled();
    });

    it('åº”è¯¥åœ¨é”™è¯¯æ—¶å›æ»šäº‹åŠ¡', async () => {
      const mockClient = {
        query: jest.fn()
          .mockResolvedValueOnce({ rows: [] }) // BEGIN
          .mockRejectedValueOnce(new Error('Query failed')), // å¤±è´¥çš„æŸ¥è¯¢
        release: jest.fn()
      };
      mockPool.connect.mockResolvedValue(mockClient);

      await expect(
        client.executeTransaction(async (tx) => {
          await tx.query('INVALID QUERY');
        })
      ).rejects.toThrow('Query failed');

      expect(mockClient.query).toHaveBeenCalledWith('ROLLBACK');
    });
  });
});
```

#### **æ··åˆå­˜å‚¨ç­–ç•¥æµ‹è¯•**

**æµ‹è¯•æ–‡ä»¶ï¼š`tests/unit/models/database.test.js`**

```javascript
describe('DatabaseClient (Hybrid Storage)', () => {
  let database;
  let mockPostgres;
  let mockRedis;

  beforeEach(() => {
    mockPostgres = {
      getApiKey: jest.fn(),
      setApiKey: jest.fn(),
      deleteApiKey: jest.fn()
    };

    mockRedis = {
      getApiKey: jest.fn(),
      setApiKey: jest.fn(),
      deleteApiKey: jest.fn()
    };

    database = new DatabaseClient({
      postgres: mockPostgres,
      redis: mockRedis
    });
  });

  describe('Read Strategy - Cache First', () => {
    it('åº”è¯¥ä¼˜å…ˆä»ç¼“å­˜è¯»å–æ•°æ®', async () => {
      const cachedData = { id: 'test-id', name: 'Cached Key' };
      mockRedis.getApiKey.mockResolvedValue(cachedData);

      const result = await database.getApiKey('test-id');

      expect(result).toEqual(cachedData);
      expect(mockRedis.getApiKey).toHaveBeenCalledWith('test-id');
      expect(mockPostgres.getApiKey).not.toHaveBeenCalled();
    });

    it('ç¼“å­˜æœªå‘½ä¸­æ—¶åº”è¯¥ä»ä¸»å­˜å‚¨è¯»å–', async () => {
      const dbData = { id: 'test-id', name: 'DB Key' };
      mockRedis.getApiKey.mockResolvedValue(null);
      mockPostgres.getApiKey.mockResolvedValue(dbData);

      const result = await database.getApiKey('test-id');

      expect(result).toEqual(dbData);
      expect(mockRedis.getApiKey).toHaveBeenCalledWith('test-id');
      expect(mockPostgres.getApiKey).toHaveBeenCalledWith('test-id');
      expect(mockRedis.setApiKey).toHaveBeenCalledWith('test-id', dbData, 3600);
    });
  });

  describe('Write Strategy - Write Through', () => {
    it('åº”è¯¥åŒæ—¶å†™å…¥ä¸»å­˜å‚¨å’Œç¼“å­˜', async () => {
      const keyData = { name: 'New Key', permissions: 'all' };
      mockPostgres.setApiKey.mockResolvedValue({ success: true });
      mockRedis.setApiKey.mockResolvedValue(true);

      await database.setApiKey('test-id', keyData);

      expect(mockPostgres.setApiKey).toHaveBeenCalledWith('test-id', keyData);
      expect(mockRedis.setApiKey).toHaveBeenCalledWith('test-id', keyData, 3600);
    });

    it('ä¸»å­˜å‚¨å¤±è´¥æ—¶åº”è¯¥æŠ›å‡ºé”™è¯¯', async () => {
      mockPostgres.setApiKey.mockRejectedValue(new Error('DB Error'));

      await expect(
        database.setApiKey('test-id', { name: 'Key' })
      ).rejects.toThrow('DB Error');

      expect(mockRedis.setApiKey).not.toHaveBeenCalled();
    });
  });
});
```

### 2. æœåŠ¡å±‚æµ‹è¯•

#### **API Key æœåŠ¡æµ‹è¯•**

**æµ‹è¯•æ–‡ä»¶ï¼š`tests/unit/services/apiKeyService.test.js`**

```javascript
describe('ApiKeyService', () => {
  let service;
  let mockDatabase;

  beforeEach(() => {
    mockDatabase = {
      getApiKey: jest.fn(),
      setApiKey: jest.fn(),
      validateApiKey: jest.fn()
    };

    service = new ApiKeyService({ database: mockDatabase });
  });

  describe('generateApiKey', () => {
    it('åº”è¯¥ç”Ÿæˆæœ‰æ•ˆçš„ API Key', async () => {
      mockDatabase.setApiKey.mockResolvedValue({ success: true });

      const result = await service.generateApiKey({
        name: 'Test Key',
        permissions: 'claude'
      });

      expect(result.success).toBe(true);
      expect(result.data.apiKey).toMatch(/^cr_[a-zA-Z0-9]{32}$/);
      expect(result.data.hashedKey).toHaveLength(64); // SHA256 hex
    });

    it('åº”è¯¥è®¾ç½®æ­£ç¡®çš„è¿‡æœŸæ—¶é—´', async () => {
      const expiresAt = new Date(Date.now() + 86400000); // 24å°æ—¶å
      mockDatabase.setApiKey.mockResolvedValue({ success: true });

      await service.generateApiKey({
        name: 'Test Key',
        expiresAt
      });

      expect(mockDatabase.setApiKey).toHaveBeenCalledWith(
        expect.any(String),
        expect.objectContaining({
          expiresAt: expiresAt.toISOString()
        })
      );
    });
  });

  describe('validateApiKey', () => {
    it('åº”è¯¥æ­£ç¡®éªŒè¯æœ‰æ•ˆçš„ API Key', async () => {
      mockDatabase.validateApiKey.mockResolvedValue({
        success: true,
        data: {
          id: 'test-id',
          permissions: 'all',
          isActive: true,
          expiresAt: null
        }
      });

      const result = await service.validateApiKey('valid-key');

      expect(result.isValid).toBe(true);
      expect(result.permissions).toBe('all');
    });

    it('åº”è¯¥æ‹’ç»è¿‡æœŸçš„ API Key', async () => {
      const expiredDate = new Date(Date.now() - 86400000); // 24å°æ—¶å‰
      mockDatabase.validateApiKey.mockResolvedValue({
        success: true,
        data: {
          id: 'test-id',
          permissions: 'all',
          isActive: true,
          expiresAt: expiredDate
        }
      });

      const result = await service.validateApiKey('expired-key');

      expect(result.isValid).toBe(false);
      expect(result.reason).toBe('expired');
    });
  });
});
```

## ğŸ”— é›†æˆæµ‹è¯•è®¡åˆ’

### 1. API ç«¯ç‚¹é›†æˆæµ‹è¯•

#### **æ ¸å¿ƒ API æµ‹è¯•**

**æµ‹è¯•æ–‡ä»¶ï¼š`tests/integration/api/messages.test.js`**

```javascript
describe('Messages API Integration', () => {
  let app;
  let database;
  let testApiKey;

  beforeAll(async () => {
    // å¯åŠ¨æµ‹è¯•æ•°æ®åº“
    database = new DatabaseClient(testConfig);
    await database.connect();

    // å¯åŠ¨æµ‹è¯•åº”ç”¨
    app = createApp({ database });

    // åˆ›å»ºæµ‹è¯• API Key
    const keyResult = await database.createApiKey({
      name: 'Integration Test Key',
      permissions: 'all'
    });
    testApiKey = keyResult.data.apiKey;
  });

  afterAll(async () => {
    await database.disconnect();
  });

  describe('POST /api/v1/messages', () => {
    it('åº”è¯¥æˆåŠŸå¤„ç† Claude æ¶ˆæ¯è¯·æ±‚', async () => {
      const response = await request(app)
        .post('/api/v1/messages')
        .set('Authorization', `Bearer ${testApiKey}`)
        .send({
          model: 'claude-3-sonnet-20240229',
          messages: [{ role: 'user', content: 'Hello, world!' }],
          max_tokens: 100
        })
        .expect(200);

      expect(response.body).toMatchObject({
        id: expect.any(String),
        model: 'claude-3-sonnet-20240229',
        usage: {
          input_tokens: expect.any(Number),
          output_tokens: expect.any(Number)
        }
      });

      // éªŒè¯ä½¿ç”¨ç»Ÿè®¡å·²è®°å½•
      const usage = await database.getUsageStats({
        apiKeyId: keyResult.data.id,
        startDate: new Date(),
        endDate: new Date()
      });

      expect(usage.data.stats).toHaveLength(1);
    });

    it('åº”è¯¥æ‹’ç»æ— æ•ˆçš„ API Key', async () => {
      await request(app)
        .post('/api/v1/messages')
        .set('Authorization', 'Bearer invalid-key')
        .send({
          model: 'claude-3-sonnet-20240229',
          messages: [{ role: 'user', content: 'Hello' }]
        })
        .expect(401);
    });

    it('åº”è¯¥å¤„ç†æµå¼å“åº”', async () => {
      const response = await request(app)
        .post('/api/v1/messages')
        .set('Authorization', `Bearer ${testApiKey}`)
        .send({
          model: 'claude-3-sonnet-20240229',
          messages: [{ role: 'user', content: 'Count from 1 to 5' }],
          stream: true
        })
        .expect(200);

      expect(response.headers['content-type']).toBe('text/event-stream');

      const chunks = response.text.split('\n\n').filter(chunk =>
        chunk.startsWith('data: ') && chunk !== 'data: [DONE]'
      );

      expect(chunks.length).toBeGreaterThan(0);

      // éªŒè¯æ¯ä¸ª chunk éƒ½æ˜¯æœ‰æ•ˆçš„ JSON
      chunks.forEach(chunk => {
        const data = JSON.parse(chunk.replace('data: ', ''));
        expect(data).toMatchObject({
          id: expect.any(String),
          delta: expect.any(Object)
        });
      });
    });
  });

  describe('Rate Limiting', () => {
    it('åº”è¯¥å¼ºåˆ¶æ‰§è¡Œé€Ÿç‡é™åˆ¶', async () => {
      // åˆ›å»ºæœ‰é™åˆ¶çš„ API Key
      const limitedKeyResult = await database.createApiKey({
        name: 'Limited Key',
        rateLimitRequests: 2,
        rateLimitWindow: 60 // 1åˆ†é’Ÿ
      });

      const limitedKey = limitedKeyResult.data.apiKey;

      // å‰ä¸¤ä¸ªè¯·æ±‚åº”è¯¥æˆåŠŸ
      await request(app)
        .post('/api/v1/messages')
        .set('Authorization', `Bearer ${limitedKey}`)
        .send({ model: 'claude-3-sonnet-20240229', messages: [{ role: 'user', content: '1' }] })
        .expect(200);

      await request(app)
        .post('/api/v1/messages')
        .set('Authorization', `Bearer ${limitedKey}`)
        .send({ model: 'claude-3-sonnet-20240229', messages: [{ role: 'user', content: '2' }] })
        .expect(200);

      // ç¬¬ä¸‰ä¸ªè¯·æ±‚åº”è¯¥è¢«é™åˆ¶
      await request(app)
        .post('/api/v1/messages')
        .set('Authorization', `Bearer ${limitedKey}`)
        .send({ model: 'claude-3-sonnet-20240229', messages: [{ role: 'user', content: '3' }] })
        .expect(429);
    });
  });
});
```

### 2. æ•°æ®åº“é›†æˆæµ‹è¯•

**æµ‹è¯•æ–‡ä»¶ï¼š`tests/integration/database/postgres.test.js`**

```javascript
describe('PostgreSQL Integration', () => {
  let client;

  beforeAll(async () => {
    client = new PostgresClient(testDbConfig);
    await client.connect();
  });

  afterAll(async () => {
    await client.disconnect();
  });

  beforeEach(async () => {
    // æ¸…ç†æµ‹è¯•æ•°æ®
    await client.query('TRUNCATE TABLE api_keys CASCADE');
    await client.query('TRUNCATE TABLE usage_statistics CASCADE');
  });

  describe('CRUD Operations', () => {
    it('åº”è¯¥æ­£ç¡®æ‰§è¡Œå®Œæ•´çš„ CRUD æµç¨‹', async () => {
      // Create
      const createResult = await client.createApiKey({
        name: 'CRUD Test Key',
        permissions: 'claude',
        tokenLimit: 1000
      });
      expect(createResult.success).toBe(true);

      const keyId = createResult.data.id;

      // Read
      const readResult = await client.getApiKey(keyId);
      expect(readResult.data.name).toBe('CRUD Test Key');
      expect(readResult.data.permissions).toBe('claude');

      // Update
      const updateResult = await client.updateApiKey(keyId, {
        name: 'Updated Key',
        tokenLimit: 2000
      });
      expect(updateResult.success).toBe(true);

      const updatedKey = await client.getApiKey(keyId);
      expect(updatedKey.data.name).toBe('Updated Key');
      expect(updatedKey.data.tokenLimit).toBe(2000);

      // Delete
      const deleteResult = await client.deleteApiKey(keyId);
      expect(deleteResult.success).toBe(true);

      const deletedKey = await client.getApiKey(keyId);
      expect(deletedKey.data).toBeNull();
    });
  });

  describe('Complex Queries', () => {
    it('åº”è¯¥æ”¯æŒå¤æ‚çš„ç»Ÿè®¡æŸ¥è¯¢', async () => {
      // å‡†å¤‡æµ‹è¯•æ•°æ®
      const keyId = await createTestApiKey(client);
      await createTestUsageData(client, keyId);

      const stats = await client.getUsageStats({
        apiKeyId: keyId,
        startDate: new Date('2025-09-01'),
        endDate: new Date('2025-09-30'),
        granularity: 'day'
      });

      expect(stats.success).toBe(true);
      expect(stats.data.stats).toHaveLength(30);
      expect(stats.data.summary.totalRequests).toBeGreaterThan(0);
    });
  });

  describe('Transaction Integrity', () => {
    it('åº”è¯¥åœ¨äº‹åŠ¡ä¸­ä¿æŒæ•°æ®ä¸€è‡´æ€§', async () => {
      await expect(
        client.executeTransaction(async (tx) => {
          // åˆ›å»º API Key
          await tx.query(`
            INSERT INTO api_keys (name, api_key_hash)
            VALUES ('Transaction Test', 'test-hash')
          `);

          // åˆ›å»ºä½¿ç”¨ç»Ÿè®¡
          await tx.query(`
            INSERT INTO usage_statistics (api_key_id, usage_date, requests_count)
            SELECT id, CURRENT_DATE, 100
            FROM api_keys WHERE name = 'Transaction Test'
          `);

          // æ•…æ„åˆ¶é€ é”™è¯¯
          throw new Error('Rollback test');
        })
      ).rejects.toThrow('Rollback test');

      // éªŒè¯äº‹åŠ¡å·²å›æ»š
      const keys = await client.query(`
        SELECT * FROM api_keys WHERE name = 'Transaction Test'
      `);
      expect(keys.rows).toHaveLength(0);
    });
  });
});
```

## ğŸ“Š æ€§èƒ½æµ‹è¯•è®¡åˆ’

### 1. åŸºå‡†æµ‹è¯•

**æµ‹è¯•æ–‡ä»¶ï¼š`tests/performance/benchmark.test.js`**

```javascript
describe('Performance Benchmarks', () => {
  let database;

  beforeAll(async () => {
    database = new DatabaseClient(perfTestConfig);
    await database.connect();
    await prepareTestData(database);
  });

  describe('Read Performance', () => {
    it('API Key éªŒè¯åº”è¯¥åœ¨ 10ms å†…å®Œæˆ', async () => {
      const hashedKey = 'test-hashed-key';

      const startTime = process.hrtime.bigint();
      await database.validateApiKey(hashedKey);
      const endTime = process.hrtime.bigint();

      const durationMs = Number(endTime - startTime) / 1000000;
      expect(durationMs).toBeLessThan(10);
    });

    it('ç¼“å­˜å‘½ä¸­ç‡åº”è¯¥å¤§äº 90%', async () => {
      const iterations = 1000;
      let cacheHits = 0;

      for (let i = 0; i < iterations; i++) {
        const startTime = process.hrtime.bigint();
        await database.getApiKey('frequently-used-key');
        const endTime = process.hrtime.bigint();

        const durationMs = Number(endTime - startTime) / 1000000;
        if (durationMs < 5) { // ç¼“å­˜å‘½ä¸­é€šå¸¸ < 5ms
          cacheHits++;
        }
      }

      const hitRate = cacheHits / iterations;
      expect(hitRate).toBeGreaterThan(0.9);
    });
  });

  describe('Write Performance', () => {
    it('æ‰¹é‡æ’å…¥æ€§èƒ½æµ‹è¯•', async () => {
      const batchSize = 1000;
      const testKeys = generateTestKeys(batchSize);

      const startTime = Date.now();
      await database.batchInsertApiKeys(testKeys);
      const endTime = Date.now();

      const duration = endTime - startTime;
      const throughput = batchSize / (duration / 1000); // keys/second

      expect(throughput).toBeGreaterThan(100); // > 100 keys/second
    });
  });

  describe('Concurrent Access', () => {
    it('å¹¶å‘è¯»å–æ€§èƒ½æµ‹è¯•', async () => {
      const concurrency = 50;
      const requestsPerWorker = 20;

      const workers = Array(concurrency).fill().map(async () => {
        for (let i = 0; i < requestsPerWorker; i++) {
          await database.getApiKey(`test-key-${Math.floor(Math.random() * 100)}`);
        }
      });

      const startTime = Date.now();
      await Promise.all(workers);
      const endTime = Date.now();

      const totalRequests = concurrency * requestsPerWorker;
      const duration = endTime - startTime;
      const throughput = totalRequests / (duration / 1000);

      expect(throughput).toBeGreaterThan(500); // > 500 req/s
    });
  });
});
```

### 2. è´Ÿè½½æµ‹è¯•

**æµ‹è¯•é…ç½®ï¼š`tests/load/artillery.yml`**

```yaml
config:
  target: 'http://localhost:3000'
  phases:
    # é¢„çƒ­é˜¶æ®µ
    - duration: 60
      arrivalRate: 10
      name: "Warmup"

    # è´Ÿè½½æµ‹è¯•
    - duration: 300
      arrivalRate: 50
      name: "Load Test"

    # å³°å€¼æµ‹è¯•
    - duration: 120
      arrivalRate: 100
      name: "Peak Load"

    # å‹åŠ›æµ‹è¯•
    - duration: 60
      arrivalRate: 200
      name: "Stress Test"

  http:
    timeout: 30
    pool: 50

scenarios:
  - name: "API Key Validation"
    weight: 40
    flow:
      - post:
          url: "/api/v1/messages"
          headers:
            Authorization: "Bearer {{ testApiKey }}"
            Content-Type: "application/json"
          json:
            model: "claude-3-sonnet-20240229"
            messages:
              - role: "user"
                content: "Hello"
            max_tokens: 50

  - name: "Usage Statistics Query"
    weight: 20
    flow:
      - get:
          url: "/admin/api/usage/{{ keyId }}"
          headers:
            Authorization: "Bearer {{ adminToken }}"

  - name: "Account Management"
    weight: 30
    flow:
      - get:
          url: "/admin/api/accounts"
          headers:
            Authorization: "Bearer {{ adminToken }}"

  - name: "Health Check"
    weight: 10
    flow:
      - get:
          url: "/health"
```

## ğŸ”„ æ•°æ®è¿ç§»æµ‹è¯•

### 1. æ•°æ®å®Œæ•´æ€§æµ‹è¯•

**æµ‹è¯•æ–‡ä»¶ï¼š`tests/migration/data-integrity.test.js`**

```javascript
describe('Data Migration Integrity', () => {
  let redis;
  let postgres;
  let migrator;

  beforeAll(async () => {
    redis = new RedisClient(testConfig);
    postgres = new PostgresClient(testConfig);
    migrator = new DataMigrator({ redis, postgres });

    await redis.connect();
    await postgres.connect();
  });

  beforeEach(async () => {
    // å‡†å¤‡ Redis æµ‹è¯•æ•°æ®
    await prepareRedisTestData(redis);
  });

  describe('API Keys Migration', () => {
    it('åº”è¯¥å®Œæ•´è¿ç§»æ‰€æœ‰ API Keys', async () => {
      const redisKeys = await redis.getAllApiKeys();

      await migrator.migrateApiKeys();

      const postgresKeys = await postgres.getAllApiKeys();

      expect(postgresKeys.length).toBe(redisKeys.length);

      // éªŒè¯æ¯ä¸ª key çš„æ•°æ®å®Œæ•´æ€§
      for (const redisKey of redisKeys) {
        const pgKey = postgresKeys.find(k => k.id === redisKey.id);
        expect(pgKey).toBeDefined();

        // éªŒè¯å…³é”®å­—æ®µ
        expect(pgKey.name).toBe(redisKey.name);
        expect(pgKey.permissions).toBe(redisKey.permissions);
        expect(pgKey.isActive).toBe(redisKey.isActive === 'true');
        expect(new Date(pgKey.createdAt)).toEqual(new Date(redisKey.createdAt));
      }
    });

    it('åº”è¯¥æ­£ç¡®å¤„ç†ç‰¹æ®Šå­—ç¬¦å’Œ JSON æ•°æ®', async () => {
      // åˆ›å»ºåŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æµ‹è¯•æ•°æ®
      await redis.setApiKey('special-test', {
        name: 'Test "Special" Characters & Symbols',
        description: `Multi-line
        description with\ttabs and 'quotes'`,
        tags: JSON.stringify(['tag1', 'tag with spaces', 'tag-with-dashes']),
        restrictedModels: JSON.stringify(['model1', 'model2'])
      });

      await migrator.migrateApiKeys();

      const migratedKey = await postgres.getApiKey('special-test');
      expect(migratedKey.data.name).toBe('Test "Special" Characters & Symbols');
      expect(migratedKey.data.tags).toEqual(['tag1', 'tag with spaces', 'tag-with-dashes']);
    });
  });

  describe('Usage Statistics Migration', () => {
    it('åº”è¯¥ä¿æŒç»Ÿè®¡æ•°æ®çš„æ•°å€¼ç²¾åº¦', async () => {
      const usageKey = 'usage:daily:test-key:2025-09-15';
      await redis.hset(usageKey, {
        requests: '1234',
        input_tokens: '56789',
        output_tokens: '98765',
        cost: '123.456789'
      });

      await migrator.migrateUsageStatistics();

      const migratedUsage = await postgres.getUsageStats({
        apiKeyId: 'test-key',
        startDate: new Date('2025-09-15'),
        endDate: new Date('2025-09-15')
      });

      const dayStats = migratedUsage.data.stats[0];
      expect(dayStats.requests).toBe(1234);
      expect(dayStats.inputTokens).toBe(56789);
      expect(dayStats.outputTokens).toBe(98765);
      expect(dayStats.cost).toBeCloseTo(123.456789, 6);
    });
  });

  describe('Migration Rollback', () => {
    it('åº”è¯¥èƒ½å¤Ÿå›æ»šå·²è¿ç§»çš„æ•°æ®', async () => {
      // æ‰§è¡Œè¿ç§»
      await migrator.migrateApiKeys();

      const beforeRollback = await postgres.getAllApiKeys();
      expect(beforeRollback.length).toBeGreaterThan(0);

      // æ‰§è¡Œå›æ»š
      await migrator.rollbackApiKeys();

      const afterRollback = await postgres.getAllApiKeys();
      expect(afterRollback.length).toBe(0);

      // éªŒè¯ Redis æ•°æ®ä»ç„¶å­˜åœ¨
      const redisKeys = await redis.getAllApiKeys();
      expect(redisKeys.length).toBeGreaterThan(0);
    });
  });
});
```

### 2. è¿ç§»æ€§èƒ½æµ‹è¯•

**æµ‹è¯•æ–‡ä»¶ï¼š`tests/migration/performance.test.js`**

```javascript
describe('Migration Performance', () => {
  it('åº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆå¤§é‡æ•°æ®è¿ç§»', async () => {
    const keyCount = 10000;
    const usageRecordCount = 100000;

    // å‡†å¤‡å¤§é‡æµ‹è¯•æ•°æ®
    await prepareLargeDataset(redis, keyCount, usageRecordCount);

    const startTime = Date.now();
    await migrator.migrateAll();
    const endTime = Date.now();

    const duration = endTime - startTime;
    const throughput = (keyCount + usageRecordCount) / (duration / 1000);

    expect(throughput).toBeGreaterThan(1000); // > 1000 records/second
    expect(duration).toBeLessThan(300000); // < 5 minutes
  });

  it('åº”è¯¥æ”¯æŒæ–­ç‚¹ç»­ä¼ ', async () => {
    await prepareLargeDataset(redis, 5000, 0);

    // å¼€å§‹è¿ç§»ä½†ä¸­é€”åœæ­¢
    const migrationPromise = migrator.migrateApiKeys();
    setTimeout(() => migrator.stop(), 5000);

    await migrationPromise.catch(() => {}); // å¿½ç•¥åœæ­¢é”™è¯¯

    const partialCount = await postgres.query('SELECT COUNT(*) FROM api_keys');
    const initialMigrated = parseInt(partialCount.rows[0].count);

    // æ¢å¤è¿ç§»
    await migrator.resumeMigration();

    const finalCount = await postgres.query('SELECT COUNT(*) FROM api_keys');
    const totalMigrated = parseInt(finalCount.rows[0].count);

    expect(totalMigrated).toBe(5000);
    expect(totalMigrated).toBeGreaterThan(initialMigrated);
  });
});
```

## ğŸš¨ æ•…éšœæ¢å¤æµ‹è¯•

### 1. é”™è¯¯å¤„ç†æµ‹è¯•

**æµ‹è¯•æ–‡ä»¶ï¼š`tests/resilience/error-handling.test.js`**

```javascript
describe('Error Handling and Resilience', () => {
  let database;

  beforeAll(async () => {
    database = new DatabaseClient(testConfig);
    await database.connect();
  });

  describe('Database Connection Failures', () => {
    it('åº”è¯¥æ­£ç¡®å¤„ç† PostgreSQL è¿æ¥æ–­å¼€', async () => {
      // æ¨¡æ‹Ÿè¿æ¥æ–­å¼€
      await database.postgres.disconnect();

      // åº”è¯¥è‡ªåŠ¨å›é€€åˆ° Redis
      const result = await database.getApiKey('test-key');
      expect(result).toBeDefined();

      // éªŒè¯é”™è¯¯è¢«è®°å½•
      const errors = await getRecentLogs('error');
      expect(errors).toContainEqual(
        expect.objectContaining({
          message: expect.stringContaining('PostgreSQL connection failed')
        })
      );
    });

    it('åº”è¯¥åœ¨è¿æ¥æ¢å¤åè‡ªåŠ¨é‡è¿', async () => {
      // é‡æ–°å¯åŠ¨ PostgreSQL
      await database.postgres.connect();

      // éªŒè¯å†™å…¥æ“ä½œæ¢å¤
      const result = await database.setApiKey('recovery-test', {
        name: 'Recovery Test'
      });

      expect(result.success).toBe(true);
    });
  });

  describe('Data Consistency Under Failures', () => {
    it('åº”è¯¥åœ¨ Redis æ•…éšœæ—¶ä¿è¯æ•°æ®å®Œæ•´æ€§', async () => {
      // åˆ›å»ºæ•°æ®
      await database.setApiKey('consistency-test', {
        name: 'Consistency Test'
      });

      // æ¨¡æ‹Ÿ Redis æ•…éšœ
      await database.redis.disconnect();

      // PostgreSQL åº”è¯¥ä»ç„¶å¯ç”¨
      const result = await database.getApiKey('consistency-test');
      expect(result.name).toBe('Consistency Test');

      // æ¢å¤ Redis
      await database.redis.connect();
    });
  });

  describe('Rate Limiting Under Load', () => {
    it('åº”è¯¥åœ¨é«˜è´Ÿè½½ä¸‹æ­£ç¡®æ‰§è¡Œé€Ÿç‡é™åˆ¶', async () => {
      const limitedKey = await createRateLimitedKey(database, {
        requests: 10,
        window: 60
      });

      // å¹¶å‘å‘é€å¤§é‡è¯·æ±‚
      const promises = Array(50).fill().map(() =>
        database.validateApiKey(limitedKey.hashedKey)
      );

      const results = await Promise.allSettled(promises);
      const successful = results.filter(r => r.status === 'fulfilled').length;
      const rateLimited = results.filter(r =>
        r.status === 'rejected' && r.reason.code === 'RATE_LIMITED'
      ).length;

      expect(successful).toBeLessThanOrEqual(10);
      expect(rateLimited).toBeGreaterThan(0);
    });
  });
});
```

## ğŸ“‹ æµ‹è¯•æ‰§è¡Œè®¡åˆ’

### æµ‹è¯•é˜¶æ®µå®‰æ’

#### **Phase 1: å¼€å‘æµ‹è¯• (æŒç»­)**
- å•å…ƒæµ‹è¯•ï¼šæ¯æ¬¡ä»£ç æäº¤æ—¶è‡ªåŠ¨è¿è¡Œ
- é›†æˆæµ‹è¯•ï¼šæ¯æ—¥æ„å»ºæ—¶è¿è¡Œ
- è¦†ç›–ç‡è¦æ±‚ï¼š> 80%

#### **Phase 2: ç³»ç»Ÿæµ‹è¯• (éƒ¨ç½²å‰)**
- åŠŸèƒ½æµ‹è¯•ï¼šå®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•
- æ€§èƒ½æµ‹è¯•ï¼šåŸºå‡†æµ‹è¯•å’Œè´Ÿè½½æµ‹è¯•
- å®‰å…¨æµ‹è¯•ï¼šè®¤è¯å’ŒæˆæƒéªŒè¯

#### **Phase 3: éªŒæ”¶æµ‹è¯• (éƒ¨ç½²å)**
- ç”Ÿäº§ç¯å¢ƒå†’çƒŸæµ‹è¯•
- ç›‘æ§å’Œå‘Šè­¦éªŒè¯
- å›æ»šæµç¨‹éªŒè¯

### æµ‹è¯•ç¯å¢ƒé…ç½®

#### **å•å…ƒæµ‹è¯•ç¯å¢ƒ**
```javascript
// jest.config.js
module.exports = {
  testEnvironment: 'node',
  testMatch: ['**/tests/unit/**/*.test.js'],
  collectCoverageFrom: [
    'src/**/*.js',
    '!src/**/*.test.js'
  ],
  coverageThreshold: {
    global: {
      branches: 80,
      functions: 80,
      lines: 80,
      statements: 80
    }
  },
  setupFilesAfterEnv: ['<rootDir>/tests/setup/unit.js']
};
```

#### **é›†æˆæµ‹è¯•ç¯å¢ƒ**
```yaml
# docker-compose.test.yml
version: '3.8'
services:
  postgres-test:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: claude_relay_test
      POSTGRES_USER: test
      POSTGRES_PASSWORD: test
    tmpfs:
      - /var/lib/postgresql/data

  redis-test:
    image: redis:7-alpine
    command: redis-server --maxmemory 128mb

  test-runner:
    build: .
    environment:
      NODE_ENV: test
      POSTGRES_HOST: postgres-test
      REDIS_HOST: redis-test
    depends_on:
      - postgres-test
      - redis-test
    command: npm run test:integration
```

### æŒç»­é›†æˆé…ç½®

#### **GitHub Actions å·¥ä½œæµ**
```yaml
name: PostgreSQL Integration Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
          POSTGRES_DB: claude_relay_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v3

      - uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'

      - run: npm ci

      - run: npm run test:unit
        env:
          CI: true

      - run: npm run test:integration
        env:
          CI: true
          POSTGRES_HOST: localhost
          POSTGRES_PASSWORD: test
          REDIS_HOST: localhost

      - run: npm run test:migration
        env:
          CI: true
          POSTGRES_HOST: localhost
          REDIS_HOST: localhost

      - name: Upload coverage reports
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage/lcov.info
```

## ğŸ“Š è´¨é‡ç½‘å…³

### éƒ¨ç½²å‰æ£€æŸ¥æ¸…å•

- [ ] å•å…ƒæµ‹è¯•é€šè¿‡ç‡ 100%
- [ ] é›†æˆæµ‹è¯•é€šè¿‡ç‡ 100%
- [ ] ä»£ç è¦†ç›–ç‡ > 80%
- [ ] æ€§èƒ½æµ‹è¯•è¾¾åˆ°åŸºå‡†è¦æ±‚
- [ ] å®‰å…¨æµ‹è¯•æ— å…³é”®æ¼æ´
- [ ] è¿ç§»æµ‹è¯•æ•°æ®ä¸€è‡´æ€§ 100%
- [ ] æ•…éšœæ¢å¤æµ‹è¯•é€šè¿‡
- [ ] æ–‡æ¡£å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡

### ç”Ÿäº§ç›‘æ§æŒ‡æ ‡

- **æœåŠ¡å¯ç”¨æ€§**: > 99.9%
- **å¹³å‡å“åº”æ—¶é—´**: < 200ms
- **95%å“åº”æ—¶é—´**: < 500ms
- **é”™è¯¯ç‡**: < 0.1%
- **æ•°æ®åº“è¿æ¥æ± åˆ©ç”¨ç‡**: < 80%
- **ç¼“å­˜å‘½ä¸­ç‡**: > 90%

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025-09-16
**è´Ÿè´£å›¢é˜Ÿ**: å…¨æ ˆæµ‹è¯•å›¢é˜Ÿ
**å®¡æ ¸çŠ¶æ€**: å¾…å®¡æ ¸